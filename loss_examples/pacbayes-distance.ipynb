{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# libraries\n",
    "import copy\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = [18, 12]\n",
    "\n",
    "# code from this library - import the lines module\n",
    "import loss_landscapes\n",
    "import loss_landscapes.metrics\n",
    "from loss_landscapes.model_interface.model_wrapper import ModelWrapper, wrap_model\n",
    "from loss_landscapes.model_interface.model_parameters import ModelParameters, rand_u_like, rand_n_like, orthogonal_to\n",
    "from loss_landscapes.contrib.functions import SimpleWarmupCaller, SimpleLossEvalCaller, log_refined_loss, _pacbayes_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preliminary: Classifying MNIST\n",
    "\n",
    "This notebook demonstrates how to accomplish a simple task: visualizing the loss landscape of a small fully connected feed-forward neural network on the MNIST image classification task. In this section the preliminaries (the model and the training procedure) are setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training hyperparameters\n",
    "IN_DIM = 28 * 28\n",
    "OUT_DIM = 10\n",
    "LR = 10 ** -2\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 25\n",
    "# contour plot resolution\n",
    "STEPS = 20\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells in this section contain no code specific to the `loss-landscapes` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPSmall(torch.nn.Module):\n",
    "    \"\"\" Fully connected feed-forward neural network with one hidden layer. \"\"\"\n",
    "    def __init__(self, x_dim, y_dim):\n",
    "        super().__init__()\n",
    "        self.linear_1 = torch.nn.Linear(x_dim, 32)\n",
    "        self.bn = torch.nn.BatchNorm1d(32)\n",
    "        self.linear_2 = torch.nn.Linear(32, y_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.linear_1(x))\n",
    "        h = self.bn(h)\n",
    "        return F.softmax(self.linear_2(h), dim=1)\n",
    "\n",
    "\n",
    "class Flatten(object):\n",
    "    \"\"\" Transforms a PIL image to a flat numpy array. \"\"\"\n",
    "    def __call__(self, sample):\n",
    "        return np.array(sample, dtype=np.float32).flatten()    \n",
    "    \n",
    "\n",
    "def train(model, optimizer, criterion, train_loader, epochs, device):\n",
    "    \"\"\" Trains the given model with the given optimizer, loss function, etc. \"\"\"\n",
    "    model.train()\n",
    "    # train model\n",
    "    for _ in tqdm(range(epochs), 'Training'):\n",
    "        for count, batch in enumerate(train_loader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            x, y = batch\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create the model and an instance of the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download MNIST and setup data loaders\n",
    "mnist_train = datasets.MNIST(root='/global/cfs/cdirs/m636/geshi/data/', train=True, download=True, transform=Flatten())\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# define model\n",
    "model = MLPSmall(IN_DIM, OUT_DIM)\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stores the initial point in parameter space\n",
    "model_initial = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 25/25 [00:43<00:00,  1.74s/it]\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, train_loader, EPOCHS, device)\n",
    "\n",
    "model_final = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check Pac Bayes Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_accuracy(test_loader, net):\n",
    "    \"\"\"Evaluate testset accuracy of a model.\"\"\"\n",
    "    net.eval()\n",
    "    acc_sum, count = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            # send data to the GPU if cuda is availabel\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "            count += inputs.size(0)\n",
    "            \n",
    "            outputs = net(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # labels = labels.long()\n",
    "            acc_sum += torch.sum(preds == labels.data).item()\n",
    "    return acc_sum/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost  1.6319406032562256\n",
      "0.9814666666666667\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "acc = test_accuracy(train_loader, model_final)\n",
    "print('time cost ', time.time()-since)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimal_dist = _pacbayes_sigma(\n",
    "    model_final,\n",
    "    2,\n",
    "    train_loader,\n",
    "    accuracy = 0.981,\n",
    "    search_depth = 10,\n",
    "    montecarlo_samples = 10,\n",
    "    accuracy_displacement = 0.1,\n",
    "    displacement_tolerance = 1e-2,\n",
    "    n_dim = 2,\n",
    "    random = 'normal',\n",
    "    normalization = 'layer',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CRF_GPU_Env",
   "language": "python",
   "name": "crf_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
